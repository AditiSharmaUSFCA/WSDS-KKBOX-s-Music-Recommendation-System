{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:51:48.556703Z",
     "start_time": "2018-12-06T04:51:47.621922Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "import re\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from summary_fn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:52:11.766120Z",
     "start_time": "2018-12-06T04:51:48.558612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data \n",
    "train = pd.read_csv('train.csv')\n",
    "member = pd.read_csv('members.csv',parse_dates=['registration_init_time','expiration_date'])\n",
    "songs = pd.read_csv('songs.csv')\n",
    "extra_song = pd.read_csv('song_extra_info.csv')\n",
    "genre_count = pd.read_csv('msno_genre_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:52:11.799145Z",
     "start_time": "2018-12-06T04:52:11.767941Z"
    }
   },
   "outputs": [],
   "source": [
    "# Correction in column type\n",
    "member.city = member.city.astype('category')\n",
    "member.registered_via = member.registered_via.astype('category')\n",
    "songs.language = songs.language.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note we will split out data set into train/validation and test set. Will not use the test set given by Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:52:58.362092Z",
     "start_time": "2018-12-06T04:52:40.523235Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge all data files\n",
    "train = train.merge(songs, how='left', on='song_id')\n",
    "train = train.merge(member, how='left', on='msno')\n",
    "train = train.merge(extra_song, how='left', on='song_id')\n",
    "train['msno_genre_count'] = genre_count['genre_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:43:53.430081Z",
     "start_time": "2018-12-06T04:43:53.188510Z"
    }
   },
   "outputs": [],
   "source": [
    "del songs\n",
    "del member\n",
    "del extra_song\n",
    "del genre_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:45:26.082862Z",
     "start_time": "2018-12-06T04:45:26.064662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature engineering functions\n",
    "def add_datepart(x, fldname, drop=True, time=False):\n",
    "    \"Helper function that adds columns relevant to a date.\"\n",
    "    df = x.copy()\n",
    "    fld = df[fldname]\n",
    "    fld_dtype = fld.dtype\n",
    "    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        fld_dtype = np.datetime64\n",
    "\n",
    "    if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
    "    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Using isrc to extract years\n",
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Counted features\n",
    "\n",
    "def gener_id_count(x):\n",
    "    if pd.isnull(x):\n",
    "        return -1\n",
    "    else:\n",
    "        return x.count('|')+1\n",
    "\n",
    "def lyricist_count(x):\n",
    "    if pd.isnull(x):\n",
    "        return -1\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "\n",
    "def composer_count(x):\n",
    "    if pd.isnull(x):\n",
    "        return -1\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "\n",
    "def artist_count(x):\n",
    "    if pd.isnull(x):\n",
    "        return -1\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "\n",
    "def is_featured(x):\n",
    "    if 'feat' in str(x) :\n",
    "        return 1\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:45:27.771249Z",
     "start_time": "2018-12-06T04:45:27.750612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fetaure addition \n",
    "def add_days_left(train):\n",
    "    train['days_left'] = (train.expiration_date - train.registration_init_time).dt.days.astype('int')\n",
    "    return train\n",
    "\n",
    "def add_gener_count(train):\n",
    "    train['gener_count'] = train['genre_ids'].apply(gener_id_count).astype(np.int8)\n",
    "    return train\n",
    "\n",
    "def add_lyricist_count(train):\n",
    "    train['lyricist_count'] = train['lyricist'].apply(lyricist_count).astype(np.int8)\n",
    "    return train\n",
    "\n",
    "\n",
    "def add_composer_count(train):\n",
    "    train['composer_count'] = train['composer'].apply(composer_count).astype(np.int8)\n",
    "    return train\n",
    "\n",
    "\n",
    "def add_artist_count(train):\n",
    "    train['artist_count'] = train['artist_name'].apply(artist_count).astype(np.int8)\n",
    "    return train\n",
    "\n",
    "def add_featured_song(train):\n",
    "    train['features'] = train['artist_name'].apply(is_featured).astype(np.int8)\n",
    "    return train\n",
    "\n",
    "\n",
    "def add_song_year(train):\n",
    "    train['song_year'] = train['isrc'].apply(isrc_to_year)\n",
    "    train.drop(['isrc', 'name'], axis = 1, inplace = True)\n",
    "    return train\n",
    "\n",
    "\n",
    "def add_song_play_count(train):\n",
    "    song_count = song_play_times(train['song_id'])\n",
    "    song_count_df = pd.DataFrame.from_dict(song_count,orient='index',columns=['song_play_counts'])\n",
    "    song_count_df.reset_index(level=0, inplace=True)\n",
    "    song_count_df = song_count_df.rename(columns={'index':'song_id'})\n",
    "    train = train.merge(song_count_df,how='left',on='song_id')\n",
    "    return train\n",
    "\n",
    "def add_artist_played_count(train):\n",
    "    artist_count = pd.DataFrame.from_dict(song_play_times(train['artist_name']),\n",
    "                                      orient='index',columns=['artist_song_count']).reset_index()\n",
    "    artist_count = artist_count.rename(columns={'index':'artist_name'})\n",
    "    train = train.merge(artist_count,how='left',on='artist_name')\n",
    "    return train\n",
    "\n",
    "def add_msno_appear_count(train):\n",
    "    msno_count = pd.DataFrame.from_dict(song_play_times(train['msno']),\n",
    "                                      orient='index',columns=['msno_appear_count']).reset_index()\n",
    "    msno_count = msno_count.rename(columns={'index':'msno'})\n",
    "    train = train.merge(msno_count,how='left',on='msno')\n",
    "    return train    \n",
    "    \n",
    "    \n",
    "def add_datepart_reg(train):\n",
    "    train = add_datepart(train, 'registration_init_time')\n",
    "    return train\n",
    "\n",
    "def add_datepart_exp(train):\n",
    "    train = add_datepart(train,'expiration_date')\n",
    "    return train\n",
    "\n",
    "def count_and_percent(df, colnames:list):\n",
    "    for i in colnames:\n",
    "        counter = pd.DataFrame.from_dict(Counter(df[i]),\n",
    "                       orient='index', columns=[i+'_count']).reset_index()\n",
    "        counter.columns = [i,i+'_count']\n",
    "        df = df.merge(counter, how='left',on=i)\n",
    "        agg = df.groupby(by=['msno',i]).agg({'song_id':['count']})\n",
    "        agg.columns = agg.columns.get_level_values(0)\n",
    "        agg.columns = [i+'_user_lev_c']\n",
    "        df = df.merge(agg,how='left',on=['msno',i])\n",
    "    return df\n",
    "\n",
    "def split_gener_columns(train):\n",
    "    df = train.copy()\n",
    "    df['genre_ids'] = df['genre_ids'].astype(str)\n",
    "    df = pd.concat([df,df['genre_ids'].str.split('|',expand=True)],axis=1)\n",
    "    df = df.drop(columns='genre_ids',axis= 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:46:22.082766Z",
     "start_time": "2018-12-06T04:46:22.079620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply features form pipeline\n",
    "def apply_features(train, feature_list):\n",
    "    for i in feature_list:\n",
    "        train = i(train)\n",
    "    return train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:46:22.504490Z",
     "start_time": "2018-12-06T04:46:22.494594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill NA values\n",
    "def fillna_nan(df, cat_list, contlist):\n",
    "    train = df.copy()\n",
    "    for col in cat_list:\n",
    "        train[col] = train[col].fillna('nan')\n",
    "    for col in contlist:\n",
    "        train[col] = train[col].fillna(-1)\n",
    "    return train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:46:23.090680Z",
     "start_time": "2018-12-06T04:46:23.070410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoding the data \n",
    "def encoder(train):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for column_name in train.columns:\n",
    "            if train[column_name].dtype.name in ['category', 'object']:\n",
    "                train[column_name] = le.fit_transform(train[column_name].astype(str))\n",
    "            else:\n",
    "                pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:50:52.566954Z",
     "start_time": "2018-12-06T04:46:33.748241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying pipeline\n",
    "\n",
    "features_pipeline = [add_days_left, add_datepart_reg, add_datepart_exp, add_gener_count, \n",
    "                     add_lyricist_count,add_composer_count, add_artist_count, add_featured_song, \n",
    "                     add_song_year,add_song_play_count, add_artist_played_count, add_msno_appear_count]\n",
    "\n",
    "x = apply_features(train, features_pipeline)\n",
    "del train\n",
    "# Few more features\n",
    "collist = ['source_system_tab', 'source_screen_name', 'source_type', 'artist_name',\n",
    "       'composer', 'lyricist']\n",
    "x = count_and_percent(x,collist)\n",
    "x = split_gener_columns(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-06T04:51:11.962Z"
    }
   },
   "outputs": [],
   "source": [
    "#testing add_datepart\n",
    "\n",
    "#print(x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-06T04:51:42.977068Z",
     "start_time": "2018-12-06T04:51:42.913430Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d18ae917f578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# testing add_datepart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m'expiration_Is_month_end'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#testing isrc_to_year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m'expiration_Year'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# testing add_datepart\n",
    "assert 'expiration_Is_month_end' in x\n",
    "\n",
    "#testing isrc_to_year\n",
    "assert 'expiration_Year' in x\n",
    "assert len(x['expiration_Year']) != 0\n",
    "\n",
    "#testing gener_id_count\n",
    "assert 'gener_count' in x\n",
    "assert len(x['gener_count']) != 0\n",
    "\n",
    "#testing composer_count\n",
    "assert 'composer_count' in x\n",
    "assert len(x['composer_count']) != 0\n",
    "\n",
    "#testing lyricist_count\n",
    "assert 'lyricist_count' in x\n",
    "assert len(x['lyricists_count']) != 0\n",
    "\n",
    "#testing is_feat\n",
    "assert 'features' in x\n",
    "assert len(x['features']) != 0\n",
    "\n",
    "#testing artist_count\n",
    "assert 'artist_count' in x\n",
    "assert len(x['artist_count']) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing add_days_left\n",
    "assert 'days_left' in x\n",
    "assert len(x['days_left']) != 0\n",
    "\n",
    "#testing add_song_play_count\n",
    "assert 'song_play_count' in x\n",
    "assert len(x['song_play_count']) != 0\n",
    "\n",
    "#testing add_artist_played_count\n",
    "assert 'artist_song_count' in x\n",
    "assert len(x['song_play_count']) != 0\n",
    "\n",
    "#testing add_msno_appear_count\n",
    "assert 'msno_appear_count' in x\n",
    "assert len(x['msno_appear_count']) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imputation block\n",
    "\n",
    "cat_nan_list = ['msno', 'song_id', 'source_screen_name', \n",
    "    'source_system_tab', 'source_type', \n",
    "    'artist_name', 'composer', 'lyricist', 'gender']\n",
    "cont_nan_list = ['song_length','language', 'song_year']\n",
    "\n",
    "x = fillna_nan(x, cat_nan_list, cont_nan_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv('features_train_data.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('features_train_data.csv')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(x.head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test validation split\n",
    "X = x.drop(columns='target',axis=1)\n",
    "y = x['target']\n",
    "\n",
    "X = X.fillna(-1)\n",
    "\n",
    "X_train_all, X_test, y_train_all, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampled train data\n",
    "idx = random.sample(range(0,X_train.shape[0]), 500000)\n",
    "X_train_sampled = X_train.iloc[idx]\n",
    "y_train_sampled = y_train.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
